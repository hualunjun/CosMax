

********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 



********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 



********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 



********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 



********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 



********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 

2024-05-17 17:03:21,192-teacher
2024-05-17 17:03:21,193-DataParallel(
  (module): MisakaNet(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Identity()
    )
    (fc): incrementalDiscriminatorHead()
  )
)
2024-05-17 17:03:21,196-student
2024-05-17 17:03:21,196-DataParallel(
  (module): MisakaNet(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Identity()
    )
    (fc): incrementalDiscriminatorHead()
  )
)
2024-05-17 17:03:21,208-LR = 0.100000 

2024-05-17 17:04:40,455-0 
:loss1=6.97117, loss2=0.00000, loss3=0.00000, trainAcc=0.28474, loss1=1.90597, loss2=0.00000, loss3=0.00000, validAcc=0.32316
2024-05-17 17:04:47,383-1 
:loss1=5.36140, loss2=0.00000, loss3=0.00000, trainAcc=0.57444, loss1=1.88629, loss2=0.00000, loss3=0.00000, validAcc=0.31807
2024-05-17 17:04:54,478-2 
:loss1=4.37515, loss2=0.00000, loss3=0.00000, trainAcc=0.62717, loss1=1.41374, loss2=0.00000, loss3=0.00000, validAcc=0.44529
2024-05-17 17:05:01,592-3 
:loss1=3.52956, loss2=0.00000, loss3=0.00000, trainAcc=0.68486, loss1=1.15043, loss2=0.00000, loss3=0.00000, validAcc=0.58779
2024-05-17 17:05:08,654-4 
:loss1=2.98764, loss2=0.00000, loss3=0.00000, trainAcc=0.75806, loss1=0.98874, loss2=0.00000, loss3=0.00000, validAcc=0.71756
2024-05-17 17:05:15,687-5 
:loss1=2.49581, loss2=0.00000, loss3=0.00000, trainAcc=0.80893, loss1=0.91713, loss2=0.00000, loss3=0.00000, validAcc=0.75827
2024-05-17 17:05:22,796-6 
:loss1=2.08515, loss2=0.00000, loss3=0.00000, trainAcc=0.86663, loss1=0.73870, loss2=0.00000, loss3=0.00000, validAcc=0.79898
2024-05-17 17:05:30,045-7 
:loss1=1.83592, loss2=0.00000, loss3=0.00000, trainAcc=0.88958, loss1=0.70139, loss2=0.00000, loss3=0.00000, validAcc=0.81934
2024-05-17 17:05:37,202-8 
:loss1=1.57947, loss2=0.00000, loss3=0.00000, trainAcc=0.92246, loss1=0.60927, loss2=0.00000, loss3=0.00000, validAcc=0.82697
2024-05-17 17:05:44,384-9 
:loss1=1.36062, loss2=0.00000, loss3=0.00000, trainAcc=0.94107, loss1=0.67162, loss2=0.00000, loss3=0.00000, validAcc=0.84987
2024-05-17 17:05:51,403-10 
:loss1=1.21072, loss2=0.00000, loss3=0.00000, trainAcc=0.95658, loss1=0.61609, loss2=0.00000, loss3=0.00000, validAcc=0.87023
2024-05-17 17:05:58,434-11 
:loss1=1.10090, loss2=0.00000, loss3=0.00000, trainAcc=0.96340, loss1=0.53982, loss2=0.00000, loss3=0.00000, validAcc=0.88550
2024-05-17 17:06:05,647-12 
:loss1=1.00070, loss2=0.00000, loss3=0.00000, trainAcc=0.97022, loss1=0.53635, loss2=0.00000, loss3=0.00000, validAcc=0.88804
2024-05-17 17:06:12,683-13 
:loss1=0.91280, loss2=0.00000, loss3=0.00000, trainAcc=0.98077, loss1=0.59760, loss2=0.00000, loss3=0.00000, validAcc=0.88295
2024-05-17 17:06:19,943-14 
:loss1=0.82141, loss2=0.00000, loss3=0.00000, trainAcc=0.98139, loss1=0.53923, loss2=0.00000, loss3=0.00000, validAcc=0.88550
2024-05-17 17:06:27,045-15 
:loss1=0.79725, loss2=0.00000, loss3=0.00000, trainAcc=0.98883, loss1=0.52475, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:06:33,999-16 
:loss1=0.75464, loss2=0.00000, loss3=0.00000, trainAcc=0.98635, loss1=0.62175, loss2=0.00000, loss3=0.00000, validAcc=0.88041
2024-05-17 17:06:41,181-17 
:loss1=0.69681, loss2=0.00000, loss3=0.00000, trainAcc=0.99132, loss1=0.52091, loss2=0.00000, loss3=0.00000, validAcc=0.88804
2024-05-17 17:06:48,580-18 
:loss1=0.65041, loss2=0.00000, loss3=0.00000, trainAcc=0.99007, loss1=0.47464, loss2=0.00000, loss3=0.00000, validAcc=0.89059
2024-05-17 17:06:55,841-19 
:loss1=0.63526, loss2=0.00000, loss3=0.00000, trainAcc=0.99566, loss1=0.52546, loss2=0.00000, loss3=0.00000, validAcc=0.88804
2024-05-17 17:07:03,221-20 
:loss1=0.58056, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.53653, loss2=0.00000, loss3=0.00000, validAcc=0.89059
2024-05-17 17:07:10,317-21 
:loss1=0.57016, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.42314, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:07:17,398-22 
:loss1=0.55691, loss2=0.00000, loss3=0.00000, trainAcc=0.99752, loss1=0.44590, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:07:24,572-23 
:loss1=0.51933, loss2=0.00000, loss3=0.00000, trainAcc=0.99566, loss1=0.42764, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:07:31,725-24 
:loss1=0.48992, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.41301, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:07:39,202-25 
:loss1=0.49709, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.49452, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:07:46,381-26 
:loss1=0.44685, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.44064, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:07:53,558-27 
:loss1=0.45737, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.42687, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:08:00,798-28 
:loss1=0.43461, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.58194, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:08:08,115-29 
:loss1=0.43575, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.42462, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:08:08,117-LR = 0.010000 

2024-05-17 17:08:15,502-30 
:loss1=0.41324, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.39378, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:08:22,836-31 
:loss1=0.40146, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.42236, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:08:30,070-32 
:loss1=0.40091, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.40527, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:08:37,244-33 
:loss1=0.39072, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.38319, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:08:44,471-34 
:loss1=0.38574, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39943, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:08:51,813-35 
:loss1=0.38740, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.44967, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:08:59,069-36 
:loss1=0.38785, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.42379, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:09:06,272-37 
:loss1=0.39840, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.46414, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:09:13,451-38 
:loss1=0.38503, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.49675, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:09:20,666-39 
:loss1=0.39163, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.45543, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:09:27,895-40 
:loss1=0.38021, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.41810, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:09:35,119-41 
:loss1=0.38787, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.42229, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:09:42,639-42 
:loss1=0.38654, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.35957, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:09:49,952-43 
:loss1=0.37476, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.38230, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:09:57,436-44 
:loss1=0.37711, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.38610, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:10:04,577-45 
:loss1=0.38062, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.57035, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:10:11,791-46 
:loss1=0.38334, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.40995, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:10:18,980-47 
:loss1=0.36686, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.41615, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:10:26,199-48 
:loss1=0.36158, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39247, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:10:33,335-49 
:loss1=0.36982, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.37052, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:10:40,379-50 
:loss1=0.37309, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.49775, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:10:47,460-51 
:loss1=0.35620, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.40724, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:10:54,584-52 
:loss1=0.35619, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.43643, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:11:01,651-53 
:loss1=0.37016, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.36314, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:11:08,874-54 
:loss1=0.36661, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.42825, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:11:15,892-55 
:loss1=0.36598, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39185, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:11:22,978-56 
:loss1=0.36268, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.46058, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:11:30,337-57 
:loss1=0.36429, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.43356, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:11:37,549-58 
:loss1=0.35787, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39359, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:11:44,699-59 
:loss1=0.36110, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39105, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:11:44,700-LR = 0.001000 

2024-05-17 17:11:51,901-60 
:loss1=0.36643, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.45566, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:11:59,143-61 
:loss1=0.36211, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.37499, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:12:06,335-62 
:loss1=0.36660, loss2=0.00000, loss3=0.00000, trainAcc=0.99690, loss1=0.50664, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:12:13,378-63 
:loss1=0.35371, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.41795, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:12:20,402-64 
:loss1=0.37229, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.52058, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:12:27,480-65 
:loss1=0.35368, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.36871, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:12:34,578-66 
:loss1=0.35458, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.52274, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:12:41,792-67 
:loss1=0.35240, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.40681, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:12:48,884-68 
:loss1=0.34963, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39118, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:12:55,890-69 
:loss1=0.35570, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39972, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:13:02,949-70 
:loss1=0.36871, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.45318, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:13:10,082-71 
:loss1=0.35341, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.45180, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:13:17,243-72 
:loss1=0.34658, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.42612, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:13:24,304-73 
:loss1=0.35022, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.46354, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:13:31,692-74 
:loss1=0.36259, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.40600, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:13:38,863-75 
:loss1=0.35703, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.46244, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:13:45,838-76 
:loss1=0.36507, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.45070, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:13:52,876-77 
:loss1=0.35294, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.44103, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:13:59,905-78 
:loss1=0.36994, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.42911, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:14:07,141-79 
:loss1=0.36167, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.44094, loss2=0.00000, loss3=0.00000, validAcc=0.91603
2024-05-17 17:14:14,223-80 
:loss1=0.35514, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.45414, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:14:21,268-81 
:loss1=0.34314, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.38472, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:14:28,357-82 
:loss1=0.34500, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.47616, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:14:35,459-83 
:loss1=0.33744, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.43087, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:14:42,648-84 
:loss1=0.36156, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.36862, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:14:49,734-85 
:loss1=0.36332, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.54320, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:14:56,913-86 
:loss1=0.36721, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.37068, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:15:04,046-87 
:loss1=0.34890, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.42392, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:15:11,089-88 
:loss1=0.34909, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.40396, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:15:18,075-89 
:loss1=0.34774, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.38306, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:15:18,077-LR = 0.000100 

2024-05-17 17:15:25,150-90 
:loss1=0.37210, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.41806, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:15:32,205-91 
:loss1=0.35609, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.40671, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:15:39,298-92 
:loss1=0.35212, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.38980, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:15:46,481-93 
:loss1=0.36230, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.43995, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:15:53,611-94 
:loss1=0.35629, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.42029, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:16:00,766-95 
:loss1=0.36198, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.49613, loss2=0.00000, loss3=0.00000, validAcc=0.91349
2024-05-17 17:16:07,865-96 
:loss1=0.34060, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.41516, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:16:14,953-97 
:loss1=0.35629, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39045, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:16:22,006-98 
:loss1=0.34577, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.42456, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 17:16:29,068-99 
:loss1=0.35010, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.38679, loss2=0.00000, loss3=0.00000, validAcc=0.91094


********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 

2024-05-17 17:26:00,935-teacher
2024-05-17 17:26:00,936-DataParallel(
  (module): MisakaNet(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Identity()
    )
    (fc): incrementalDiscriminatorHead()
  )
)
2024-05-17 17:26:00,939-student
2024-05-17 17:26:00,939-DataParallel(
  (module): MisakaNet(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Identity()
    )
    (fc): incrementalDiscriminatorHead()
  )
)
2024-05-17 17:26:00,951-LR = 0.100000 

2024-05-17 17:27:20,015-0 
:loss1=7.11404, loss2=0.00000, loss3=0.00000, trainAcc=0.27171, loss1=1.94566, loss2=0.00000, loss3=0.00000, validAcc=0.30534
2024-05-17 17:27:27,012-1 
:loss1=5.42094, loss2=0.00000, loss3=0.00000, trainAcc=0.57878, loss1=1.89999, loss2=0.00000, loss3=0.00000, validAcc=0.26972
2024-05-17 17:27:34,006-2 
:loss1=4.52430, loss2=0.00000, loss3=0.00000, trainAcc=0.64640, loss1=1.55939, loss2=0.00000, loss3=0.00000, validAcc=0.42494
2024-05-17 17:27:41,006-3 
:loss1=3.71963, loss2=0.00000, loss3=0.00000, trainAcc=0.67308, loss1=1.17054, loss2=0.00000, loss3=0.00000, validAcc=0.56489
2024-05-17 17:27:48,161-4 
:loss1=3.11784, loss2=0.00000, loss3=0.00000, trainAcc=0.75682, loss1=0.98375, loss2=0.00000, loss3=0.00000, validAcc=0.70992
2024-05-17 17:27:55,473-5 
:loss1=2.63501, loss2=0.00000, loss3=0.00000, trainAcc=0.80769, loss1=0.92040, loss2=0.00000, loss3=0.00000, validAcc=0.73537
2024-05-17 17:28:02,560-6 
:loss1=2.22327, loss2=0.00000, loss3=0.00000, trainAcc=0.86290, loss1=0.74042, loss2=0.00000, loss3=0.00000, validAcc=0.78626
2024-05-17 17:28:09,612-7 
:loss1=1.92819, loss2=0.00000, loss3=0.00000, trainAcc=0.87035, loss1=0.68952, loss2=0.00000, loss3=0.00000, validAcc=0.81170
2024-05-17 17:28:16,596-8 
:loss1=1.69818, loss2=0.00000, loss3=0.00000, trainAcc=0.89950, loss1=0.65082, loss2=0.00000, loss3=0.00000, validAcc=0.82697
2024-05-17 17:28:23,864-9 
:loss1=1.46112, loss2=0.00000, loss3=0.00000, trainAcc=0.92742, loss1=0.59476, loss2=0.00000, loss3=0.00000, validAcc=0.84987
2024-05-17 17:28:31,080-10 
:loss1=1.31043, loss2=0.00000, loss3=0.00000, trainAcc=0.94479, loss1=0.57488, loss2=0.00000, loss3=0.00000, validAcc=0.85496
2024-05-17 17:28:38,333-11 
:loss1=1.14838, loss2=0.00000, loss3=0.00000, trainAcc=0.96154, loss1=0.51457, loss2=0.00000, loss3=0.00000, validAcc=0.86005
2024-05-17 17:28:45,261-12 
:loss1=1.05957, loss2=0.00000, loss3=0.00000, trainAcc=0.96588, loss1=0.58809, loss2=0.00000, loss3=0.00000, validAcc=0.87277
2024-05-17 17:28:52,340-13 
:loss1=0.96252, loss2=0.00000, loss3=0.00000, trainAcc=0.97146, loss1=0.57312, loss2=0.00000, loss3=0.00000, validAcc=0.86514
2024-05-17 17:28:59,297-14 
:loss1=0.88768, loss2=0.00000, loss3=0.00000, trainAcc=0.98511, loss1=0.52480, loss2=0.00000, loss3=0.00000, validAcc=0.87532
2024-05-17 17:29:06,410-15 
:loss1=0.84849, loss2=0.00000, loss3=0.00000, trainAcc=0.98511, loss1=0.46435, loss2=0.00000, loss3=0.00000, validAcc=0.88041
2024-05-17 17:29:13,513-16 
:loss1=0.78538, loss2=0.00000, loss3=0.00000, trainAcc=0.98697, loss1=0.50383, loss2=0.00000, loss3=0.00000, validAcc=0.88041
2024-05-17 17:29:20,497-17 
:loss1=0.75957, loss2=0.00000, loss3=0.00000, trainAcc=0.98697, loss1=0.53059, loss2=0.00000, loss3=0.00000, validAcc=0.88550
2024-05-17 17:29:27,608-18 
:loss1=0.70347, loss2=0.00000, loss3=0.00000, trainAcc=0.99256, loss1=0.47647, loss2=0.00000, loss3=0.00000, validAcc=0.88804
2024-05-17 17:29:34,775-19 
:loss1=0.64538, loss2=0.00000, loss3=0.00000, trainAcc=0.99566, loss1=0.48554, loss2=0.00000, loss3=0.00000, validAcc=0.89059
2024-05-17 17:29:41,960-20 
:loss1=0.62479, loss2=0.00000, loss3=0.00000, trainAcc=0.99194, loss1=0.57582, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:29:49,180-21 
:loss1=0.59158, loss2=0.00000, loss3=0.00000, trainAcc=0.99504, loss1=0.41410, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:29:56,568-22 
:loss1=0.57569, loss2=0.00000, loss3=0.00000, trainAcc=0.99628, loss1=0.41562, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:30:03,983-23 
:loss1=0.52833, loss2=0.00000, loss3=0.00000, trainAcc=0.99752, loss1=0.43637, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:30:11,256-24 
:loss1=0.50662, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.52562, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:30:18,661-25 
:loss1=0.49750, loss2=0.00000, loss3=0.00000, trainAcc=0.99752, loss1=0.42138, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:30:26,003-26 
:loss1=0.48243, loss2=0.00000, loss3=0.00000, trainAcc=0.99752, loss1=0.41160, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:30:33,291-27 
:loss1=0.45298, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.40484, loss2=0.00000, loss3=0.00000, validAcc=0.89059
2024-05-17 17:30:40,744-28 
:loss1=0.46418, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.43894, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:30:48,128-29 
:loss1=0.43839, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.50529, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:30:48,129-LR = 0.010000 

2024-05-17 17:30:55,408-30 
:loss1=0.42312, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.41555, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:31:02,821-31 
:loss1=0.42011, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.58364, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:31:10,174-32 
:loss1=0.40672, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.47683, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:31:17,643-33 
:loss1=0.40745, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.40769, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:31:25,101-34 
:loss1=0.40902, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.43402, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:31:32,435-35 
:loss1=0.40709, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.47076, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:31:39,766-36 
:loss1=0.42072, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.37591, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:31:47,064-37 
:loss1=0.41655, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.40558, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:31:54,249-38 
:loss1=0.40006, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.46156, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:32:01,356-39 
:loss1=0.38844, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.43626, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:32:08,532-40 
:loss1=0.39293, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.41584, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:32:15,651-41 
:loss1=0.39498, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.43340, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:32:22,802-42 
:loss1=0.38284, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.41873, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:32:29,872-43 
:loss1=0.38587, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.40675, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:32:37,069-44 
:loss1=0.41369, loss2=0.00000, loss3=0.00000, trainAcc=0.99690, loss1=0.50077, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:32:44,276-45 
:loss1=0.38951, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.48162, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:32:51,530-46 
:loss1=0.39381, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.44912, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:32:58,841-47 
:loss1=0.38229, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.39546, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:33:06,149-48 
:loss1=0.37828, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.46378, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:33:13,321-49 
:loss1=0.38921, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.37887, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:33:20,484-50 
:loss1=0.39252, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.40886, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:33:27,575-51 
:loss1=0.39414, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.47752, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:33:34,703-52 
:loss1=0.37863, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.44387, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:33:41,744-53 
:loss1=0.39597, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.59350, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:33:49,018-54 
:loss1=0.38190, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.47438, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 17:33:56,296-55 
:loss1=0.36888, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.41516, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:34:03,433-56 
:loss1=0.37571, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.48045, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:34:10,619-57 
:loss1=0.39046, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.42118, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:34:17,842-58 
:loss1=0.37172, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.42321, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:34:24,856-59 
:loss1=0.38509, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.40439, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:34:24,858-LR = 0.001000 

2024-05-17 17:34:31,907-60 
:loss1=0.36788, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.43518, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:34:39,053-61 
:loss1=0.36688, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.43812, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:34:46,121-62 
:loss1=0.36413, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.43180, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:34:53,247-63 
:loss1=0.36968, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.39653, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:35:00,438-64 
:loss1=0.38679, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.43790, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:35:07,749-65 
:loss1=0.38005, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.49496, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:35:14,891-66 
:loss1=0.36775, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.38400, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:35:22,166-67 
:loss1=0.37450, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.46692, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:35:29,426-68 
:loss1=0.36753, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.44331, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:35:36,731-69 
:loss1=0.37432, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.39181, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:35:43,917-70 
:loss1=0.37668, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.45153, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:35:51,059-71 
:loss1=0.37325, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.61827, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:35:58,205-72 
:loss1=0.37101, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.41485, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:36:05,314-73 
:loss1=0.36591, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.40560, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:36:12,482-74 
:loss1=0.36021, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.50879, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:36:19,641-75 
:loss1=0.37716, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.48166, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:36:26,841-76 
:loss1=0.36598, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.44037, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:36:34,179-77 
:loss1=0.37423, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.42175, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:36:41,492-78 
:loss1=0.38479, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39699, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:36:48,719-79 
:loss1=0.36830, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.42281, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:36:55,959-80 
:loss1=0.37107, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.44657, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:37:03,126-81 
:loss1=0.36603, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.42194, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:37:10,393-82 
:loss1=0.36978, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.44794, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:37:17,847-83 
:loss1=0.37015, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.42292, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:37:25,128-84 
:loss1=0.36429, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.43713, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:37:32,159-85 
:loss1=0.37499, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.44243, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:37:39,329-86 
:loss1=0.37006, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.51457, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:37:46,429-87 
:loss1=0.37827, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.37652, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 17:37:53,543-88 
:loss1=0.37108, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.45157, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:38:00,717-89 
:loss1=0.37419, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.43859, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:38:00,718-LR = 0.000100 

2024-05-17 17:38:07,770-90 
:loss1=0.38256, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.44769, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:38:14,898-91 
:loss1=0.37547, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.39513, loss2=0.00000, loss3=0.00000, validAcc=0.89822
2024-05-17 17:38:22,043-92 
:loss1=0.36898, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.38521, loss2=0.00000, loss3=0.00000, validAcc=0.89567
2024-05-17 17:38:29,308-93 
:loss1=0.37348, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.39473, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:38:36,570-94 
:loss1=0.37266, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.51542, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:38:43,730-95 
:loss1=0.36815, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.40970, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:38:50,988-96 
:loss1=0.36990, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.44334, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 17:38:58,267-97 
:loss1=0.36765, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.38363, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:39:05,498-98 
:loss1=0.37589, loss2=0.00000, loss3=0.00000, trainAcc=0.99938, loss1=0.39715, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 17:39:12,619-99 
:loss1=0.38349, loss2=0.00000, loss3=0.00000, trainAcc=1.00000, loss1=0.45076, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 17:39:14,087-step=0, testAcc=0.90076


********************************** the config of exeperience ********************************** 

import torch
from torchvision import transforms
import numpy as np
import os


class Config:
    def __init__(self, step):

        self.TrainId = "face-train-b20-20"
        self.batchsz = 128
        self.dataset_name = "face"
        self.step = step
        self.first_setp_cls = 20
        self.incr_cls = 20
        self.classNum = self.first_setp_cls + self.incr_cls*(self.step)
        self.preClassNum = 0 if self.step == 0 else self.first_setp_cls + self.incr_cls * (self.step - 1)
        self.reserveNum = 4

        self.trainDir = "./datasets/"+self.dataset_name+"/train"
        self.testDir = "./datasets/"+self.dataset_name+"/test"
        self.inversionDir = "./datasets/"+self.dataset_name+"/reserve"
        self.allClassNum = len(os.listdir(self.trainDir))

        self.pretrain_model_path = "./datasets/barlowtwins.pth"
        self.model_path = "./model/" + self.TrainId +'-'+str(self.step) + ".pth"

        self.train_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.RandomCrop([224, 224], padding=28, pad_if_needed=False, fill=0, padding_mode='reflect'),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.test_transformer = transforms.Compose([
            # transforms.Resize([32, 32]),
            transforms.Resize([224, 224]),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # imagenet
                                 std=[0.229, 0.224, 0.225])
        ])

        self.USE_MULTI_GPU = True

        self.optimizer = "SGD"
        self.lr = 1

        self.epoch_num = 100





*********************************************************************************************** 

2024-05-17 18:39:45,582-teacher
2024-05-17 18:39:45,582-DataParallel(
  (module): MisakaNet(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Identity()
    )
    (fc): incrementalDiscriminatorHead()
  )
)
2024-05-17 18:39:45,585-student
2024-05-17 18:39:45,585-DataParallel(
  (module): MisakaNet(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Identity()
    )
    (fc): incrementalDiscriminatorHead()
  )
)
2024-05-17 18:39:45,592-LR = 0.100000 

2024-05-17 18:41:04,610-0 
:loss1=7.14311, loss2=0.00000, loss3=0.00000, trainAcc=0.25993, loss1=2.00344, loss2=0.00000, loss3=0.00000, validAcc=0.26463
2024-05-17 18:41:11,589-1 
:loss1=5.53747, loss2=0.00000, loss3=0.00000, trainAcc=0.56141, loss1=1.93673, loss2=0.00000, loss3=0.00000, validAcc=0.24936
2024-05-17 18:41:18,589-2 
:loss1=4.60703, loss2=0.00000, loss3=0.00000, trainAcc=0.62531, loss1=1.52271, loss2=0.00000, loss3=0.00000, validAcc=0.36896
2024-05-17 18:41:25,554-3 
:loss1=3.73593, loss2=0.00000, loss3=0.00000, trainAcc=0.67184, loss1=1.33272, loss2=0.00000, loss3=0.00000, validAcc=0.52926
2024-05-17 18:41:32,655-4 
:loss1=3.19786, loss2=0.00000, loss3=0.00000, trainAcc=0.73759, loss1=0.97385, loss2=0.00000, loss3=0.00000, validAcc=0.68193
2024-05-17 18:41:39,851-5 
:loss1=2.73603, loss2=0.00000, loss3=0.00000, trainAcc=0.78164, loss1=0.90291, loss2=0.00000, loss3=0.00000, validAcc=0.74809
2024-05-17 18:41:46,932-6 
:loss1=2.33405, loss2=0.00000, loss3=0.00000, trainAcc=0.83313, loss1=0.71130, loss2=0.00000, loss3=0.00000, validAcc=0.77354
2024-05-17 18:41:54,159-7 
:loss1=2.00932, loss2=0.00000, loss3=0.00000, trainAcc=0.86973, loss1=0.67244, loss2=0.00000, loss3=0.00000, validAcc=0.81170
2024-05-17 18:42:01,314-8 
:loss1=1.74317, loss2=0.00000, loss3=0.00000, trainAcc=0.89578, loss1=0.74653, loss2=0.00000, loss3=0.00000, validAcc=0.81934
2024-05-17 18:42:08,357-9 
:loss1=1.52940, loss2=0.00000, loss3=0.00000, trainAcc=0.92432, loss1=0.63478, loss2=0.00000, loss3=0.00000, validAcc=0.83206
2024-05-17 18:42:15,370-10 
:loss1=1.35908, loss2=0.00000, loss3=0.00000, trainAcc=0.93734, loss1=0.59710, loss2=0.00000, loss3=0.00000, validAcc=0.83969
2024-05-17 18:42:22,403-11 
:loss1=1.21421, loss2=0.00000, loss3=0.00000, trainAcc=0.94851, loss1=0.59500, loss2=0.00000, loss3=0.00000, validAcc=0.85751
2024-05-17 18:42:29,532-12 
:loss1=1.08688, loss2=0.00000, loss3=0.00000, trainAcc=0.95596, loss1=0.53849, loss2=0.00000, loss3=0.00000, validAcc=0.86260
2024-05-17 18:42:36,600-13 
:loss1=1.01728, loss2=0.00000, loss3=0.00000, trainAcc=0.97333, loss1=0.49122, loss2=0.00000, loss3=0.00000, validAcc=0.88295
2024-05-17 18:42:43,680-14 
:loss1=0.92465, loss2=0.00000, loss3=0.00000, trainAcc=0.97705, loss1=0.55778, loss2=0.00000, loss3=0.00000, validAcc=0.88295
2024-05-17 18:42:50,749-15 
:loss1=0.86175, loss2=0.00000, loss3=0.00000, trainAcc=0.97953, loss1=0.54511, loss2=0.00000, loss3=0.00000, validAcc=0.88550
2024-05-17 18:42:57,879-16 
:loss1=0.79299, loss2=0.00000, loss3=0.00000, trainAcc=0.98821, loss1=0.45745, loss2=0.00000, loss3=0.00000, validAcc=0.88804
2024-05-17 18:43:05,033-17 
:loss1=0.77194, loss2=0.00000, loss3=0.00000, trainAcc=0.98325, loss1=0.63230, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 18:43:12,489-18 
:loss1=0.71685, loss2=0.00000, loss3=0.00000, trainAcc=0.98821, loss1=0.59777, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 18:43:19,942-19 
:loss1=0.67052, loss2=0.00000, loss3=0.00000, trainAcc=0.99256, loss1=0.51779, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 18:43:27,031-20 
:loss1=0.62733, loss2=0.00000, loss3=0.00000, trainAcc=0.99256, loss1=0.57506, loss2=0.00000, loss3=0.00000, validAcc=0.90840
2024-05-17 18:43:34,082-21 
:loss1=0.61275, loss2=0.00000, loss3=0.00000, trainAcc=0.99566, loss1=0.52899, loss2=0.00000, loss3=0.00000, validAcc=0.89313
2024-05-17 18:43:41,061-22 
:loss1=0.58813, loss2=0.00000, loss3=0.00000, trainAcc=0.99504, loss1=0.47271, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 18:43:48,169-23 
:loss1=0.56423, loss2=0.00000, loss3=0.00000, trainAcc=0.99504, loss1=0.40608, loss2=0.00000, loss3=0.00000, validAcc=0.90076
2024-05-17 18:43:55,346-24 
:loss1=0.52267, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.47563, loss2=0.00000, loss3=0.00000, validAcc=0.90331
2024-05-17 18:44:02,574-25 
:loss1=0.51465, loss2=0.00000, loss3=0.00000, trainAcc=0.99876, loss1=0.50243, loss2=0.00000, loss3=0.00000, validAcc=0.91094
2024-05-17 18:44:09,700-26 
:loss1=0.49418, loss2=0.00000, loss3=0.00000, trainAcc=0.99690, loss1=0.41001, loss2=0.00000, loss3=0.00000, validAcc=0.90585
2024-05-17 18:44:16,808-27 
:loss1=0.49690, loss2=0.00000, loss3=0.00000, trainAcc=0.99814, loss1=0.46284, loss2=0.00000, loss3=0.00000, validAcc=0.90331
